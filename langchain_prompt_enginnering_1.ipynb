{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP40t7Zq050dG6aN++jZVKw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aananda-giri/Bootcamps/blob/langchain/langchain_prompt_enginnering_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "demo_template = '''I want you to act as a acting financial advisor for people. In an easy way, explain the basics of {financial_concept}.'''\n",
        "\n",
        "prompt=PromptTemplate(\n",
        "  input_variables=['financial_concept'],\n",
        "  template=demo_template\n",
        ")\n",
        "\n",
        "print(prompt)\n",
        "\n",
        "prompt.format(financial_concept='income tax')\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD5dWkxZI8Rw",
        "outputId": "876c6483-d0e3-48c1-c4e6-e53994dafce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['financial_concept'] input_types={} partial_variables={} template='I want you to act as a acting financial advisor for people. In an easy way, explain the basics of {financial_concept}.'\n",
            "input_variables=['financial_concept'] input_types={} partial_variables={} template='I want you to act as a acting financial advisor for people. In an easy way, explain the basics of {financial_concept}.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mo8QGe8JPLpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ2LAFi5J4G4",
        "outputId": "67de2e8a-3380-4f51-b447-6ce93f588bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GEMMA_KEY_JOKELEOPEDIA')\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"]=\"<your api key>\"\n",
        "# source: prompt templates example\n",
        "# llm = OpenAI(temperature=0.7)\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "chain1 = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "chain1.run('income tax.')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "Kw0B3uShJPjB",
        "outputId": "b7071d86-024f-4e77-9d33-1d71eb0e0448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Alright folks, let's talk about income tax – nobody's favorite topic, but definitely something you need to understand.  Think of it like this:  you earn money, and the government takes a little slice of that pie to pay for things like roads, schools, and parks.  That slice is your income tax.\\n\\nHere's the basic breakdown:\\n\\n1. **Income:** This is all the money you earn, including your salary, wages, tips, any side hustle money, and even investment earnings.\\n\\n2. **Deductions:**  Think of these as discounts on your taxes.  There are certain expenses you can deduct from your total income, which lowers the amount you're taxed on.  Common deductions include things like student loan interest, contributions to retirement accounts (like a 401(k) or IRA), and sometimes even charitable donations.  These deductions can significantly reduce your tax bill!\\n\\n3. **Taxable Income:** This is what's left after you subtract your deductions from your total income.  This is the amount the government actually uses to calculate your tax.\\n\\n4. **Tax Brackets:**  The government divides income into different levels called tax brackets.  Each bracket has a different tax rate.  The more you earn, the higher the tax rate on that portion of your income.  It's important to remember that you're not taxed at the highest rate on *all* your income, just the portion that falls within that higher bracket.\\n\\n5. **Tax Credits:** These are even better than deductions!  Credits directly reduce the amount of tax you owe, dollar for dollar.  There are credits for things like having children, going to school, or making energy-efficient home improvements.\\n\\n6. **Filing:**  Once a year, you need to file your taxes.  This is where you report your income, deductions, and credits to the government.  You can do this yourself using tax software or hire a professional to help you.\\n\\n7. **Refund or Payment:**  After filing, you'll either get a refund (if you paid more taxes than you owed throughout the year) or you'll owe the government more money.\\n\\n**Key takeaway:**  Understanding these basics can help you make smarter financial decisions.  By maximizing your deductions and credits, you can keep more of your hard-earned money.  Don't be afraid to ask questions and seek professional advice if you need it.  Taxes can seem complicated, but breaking them down into these simple steps makes them much more manageable.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.run('GDP.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "f4dsFXmwKIJo",
        "outputId": "e142acec-5001-4465-88b6-5397ca85cc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Alright folks, gather 'round! Let's talk about GDP – it sounds fancy, but it's really just a way to measure how well our country's economy is doing. Think of it like a national report card for our money-making activities.\\n\\nImagine a giant bakery.  Everything they bake and sell in a year, from cookies to cakes, adds to their total sales. GDP is like that, but for a whole country. It's the total value of *everything* produced within our borders in a year – all the goods and services, from haircuts to houses, from apps to apples.\\n\\n**Here's the simple breakdown:**\\n\\n* **Goods:**  Think tangible stuff – cars, clothes, furniture, food.\\n* **Services:**  Things people do for you – doctor visits, haircuts, concerts, online shopping deliveries.\\n\\n**Why do we care about GDP?**\\n\\nWell, if GDP is growing, it generally means the economy is doing well.  Businesses are hiring, people are spending money, and things are looking up. If GDP is shrinking, it could mean trouble – businesses might struggle, jobs could be lost, and things might feel a bit tight.\\n\\n**Think of it like this:**\\n\\n* **GDP growing = Bigger pie:** Everyone potentially gets a bigger slice.\\n* **GDP shrinking = Smaller pie:**  We all might have to make do with less.\\n\\n**Important Note:** GDP isn't a perfect measure. It doesn't tell us about things like happiness, income inequality, or environmental impact.  But it's a useful starting point for understanding how our economy is performing.\\n\\nSo, the next time you hear about GDP on the news, remember it's just a snapshot of our national economic activity.  And hopefully, it's a picture of growth and prosperity!  Any questions? Don't be shy!  (Disclaimer: I'm an AI acting as a financial advisor, not a real one.  Always consult with a qualified professional for personalized advice.)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few shot prompts\n",
        "* [reference](https://python.langchain.com/docs/how_to/few_shot_examples_chat/#create-prompt-template)"
      ],
      "metadata": {
        "id": "do7RPopzD4WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-openai langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps4t6SN0MCfc",
        "outputId": "727273f5-8528-47f7-a610-eccbe9a0d73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import  langchain_google_genai as google_genai"
      ],
      "metadata": {
        "id": "FqOHGArZMYiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"<your_google_api_key>\"\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"2 🥜 2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2 🥜 3\", \"output\": \"5\"},\n",
        "    {\"input\": \"2 🥜 4\", \"output\": \"6\"},\n",
        "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
        "    {\n",
        "        \"input\": \"Write me a poem about the moon\",\n",
        "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
        "    },\n",
        "]\n",
        "\n",
        "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
        "# embeddings = GoogleGenerativeAIEmbeddings()\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "\n",
        "'''\n",
        "this line gives an error:\n",
        "ValidationError: 1 validation error for GoogleGenerativeAIEmbeddings\n",
        "model\n",
        "  Field required [type=missing, input_value={}, input_type=dict]\n",
        "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
        "'''\n",
        "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)\n",
        "\n",
        "example_selector = SemanticSimilarityExampleSelector(\n",
        "    vectorstore=vectorstore,\n",
        "    k=2,\n",
        ")\n",
        "\n",
        "example_selector.select_examples({\"input\": \"horse\"})\n",
        "\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    input_variables=[\"input\"],\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=ChatPromptTemplate.from_messages(\n",
        "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.invoke(input=\"What's 3 🥜 3?\").to_messages())\n",
        "\n",
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.invoke(input=\"What's 3 🥜 3?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijj_EKTLMbkp",
        "outputId": "9cd5b326-9c79-4bed-c89f-7928263b82be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='2 🥜 3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={}), HumanMessage(content='2 🥜 3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={})]\n",
            "messages=[HumanMessage(content='2 🥜 3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={}), HumanMessage(content='2 🥜 3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = final_prompt | ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "chain.invoke({\"input\": \"What's 3 🦜 3?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDqLtlC1N7K4",
        "outputId": "add79a88-87c7-477e-dae1-42e3f26df034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='If 🦜 represents multiplication, then 3 🦜 3 = 9.\\n\\nIf 🦜 represents addition, then 3 🦜 3 = 6.\\n\\nIf 🦜 represents concatenation, then 3 🦜 3 = 33.\\n\\n🦜 could also represent a completely different operation.  I need more information to give you a definite answer!  Tell me what 🦜 means.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-201f13ff-bf2a-4a4d-98f6-6e501d8e29c8-0', usage_metadata={'input_tokens': 30, 'output_tokens': 85, 'total_tokens': 115, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Language Translation (krish naik openai example)\n",
        "\n",
        "# from langchain import PromptTemplate\n",
        "# template = '''In an easy way to translate the following sentence '{sentence}' into {target_language}'''\n",
        "# language_prompt = PromptTemplate(\n",
        "# input_variables=[\"sentence\", \"target_language\"],\n",
        "# template=template\n",
        "# )\n",
        "# language_prompt.format(sentencee=\"How are you\", target_language=\"hindi\")\n",
        "\n",
        "# chain2 = LLMChain(llm=llm, prompt=language_prompt)\n",
        "# chain2({'sentence':\"Hello how are you\", \"target_language\":\"hindi\"})\n",
        "\n",
        "\n",
        "# from langchain import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "# # Frist, create the list of feww shot examples\n",
        "# examples=[\n",
        "# {\"word\":\"happy\", \"antonym\":\"sad\"},\n",
        "# {\"word\":\"tall\", \"antonym\":\"short\"},\n",
        "# ]\n",
        "\n",
        "# # Next, we specify thhe template to format the examples we have provided.\n",
        "# # We usse the `promptTemplate` class for this\n",
        "# example_formatter_template = \"\"\"Word: {word}\n",
        "# Antonym: {antonym}\n",
        "# \"\"\"\n",
        "# # finally, we create the `FewShotPromptTemplate` object.\n",
        "# few_shot_prompt = FewShotPromptTemplate(\n",
        "# # These are the examples we want to inesrt into the prompt.\n",
        "# examples=examples,\n",
        "# # Thus us how we want to format the examples when we insert them into the prompt\n",
        "# example_prompt = example_prompt,\n",
        "# # The prefix is some text that goes before the examples in the prompt\n",
        "# # usually, this is where the user input will go\n",
        "# # The input variables are the variables that ahte overall prompt expects.\n",
        "# prefix=\"Give the eantonym of every inpyt\\n\",\n",
        "# # The example_seperator\n",
        "# suffix=\"Word: {input}\\n Antonym: \",\n",
        "\n",
        "# input_variables=[\"input\"],\n",
        "# # The example seperator is the string we will use to join the prefix, examples,\n",
        "# example_separator=\"\\n\",\n",
        "# )\n",
        "\n",
        "# print(few_shot_prompt.format(input='big'))\n",
        "\n",
        "# chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
        "# chain.run(\"big\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxvdvhayD28q",
        "outputId": "b3a8398e-9b03-4713-87b4-b342978afa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['sentence', 'target_language'] input_types={} partial_variables={} template='In an easy way to translate the following sentence {sentence} into {target_language}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = LLMChain(llm=llm, prompt=language_prompt)\n",
        "chain2({'sentence':\"Hello how are you\", \"target_language\":\"hindi\"})\n",
        "\n",
        "\n",
        "from langchain import PromptTemplate, FewShotPromptTemplate\n",
        "# Frist, create the list of feww shot examples\n",
        "examples=[\n",
        "  {\"word\":\"happy\", \"antonym\":\"sad\"},\n",
        "  {\"word\":\"tall\", \"antonym\":\"short\"},\n",
        "]\n",
        "\n",
        "# Next, we specify thhe template to format the examples we have provided.\n",
        "# We usse the `promptTemplate` class for this\n",
        "example_formatter_template = \"\"\"Word: {word}\n",
        "Antonym: {antonym}\n",
        "\"\"\"\n",
        "# finally, we create the `FewShotPromptTemplate` object.\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "  # These are the examples we want to inesrt into the prompt.\n",
        "  examples=examples,\n",
        "  # Thus us how we want to format the examples when we insert them into the prompt\n",
        "  example_prompt = example_prompt,\n",
        "  # The prefix is some text that goes before the examples in the prompt\n",
        "  # usually, this is where the user input will go\n",
        "  # The input variables are the variables that ahte overall prompt expects.\n",
        "  prefix=\"Give the eantonym of every inpyt\\n\",\n",
        "  # The example_seperator\n",
        "  suffix=\"Word: {input}\\n Antonym: \",\n",
        "\n",
        "  input_variables=[\"input\"],\n",
        "  # The example seperator is the string we will use to join the prefix, examples,\n",
        "  example_separator=\"\\n\",\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.format(input='big'))\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
        "chain.run(\"big\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "atEBdd13Krlk",
        "outputId": "3720258d-9529-4f20-b694-2ed35defdada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'example_selector' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-249b2a04cefb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# The input variables select the values to pass to the example_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mexample_selector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_selector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Define how each example will be formatted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# In this case, each example will become 2 messages:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'example_selector' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
        "chain.run(\"big\")"
      ],
      "metadata": {
        "id": "Dwyg86SLLXON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. gemma api key -> test it\n",
        "use gemma"
      ],
      "metadata": {
        "id": "zEPkVFidDSOe"
      }
    }
  ]
}