{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reference: https://www.youtube.com/watch?v=a4HBKEda_F8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install elasticsearch\n",
    "!uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "client_info = es.info()\n",
    "pprint(\"Connecting to the Elasticsearch\")\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "\n",
    "es.indices.delete(index=\"test_index\", ignore_unavailable=True)\n",
    "es.indices.create(index=\"test_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crerate index with shards and replicas\n",
    "'''\n",
    "* shards is the number of slices for the document\n",
    "* replicas is the number of replicas (duplicate copy of the data)\n",
    "'''\n",
    "\n",
    "es.indices.delete(index=\"test_index\", ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index=\"test_index\", settings={\n",
    "        \"number_of_shards\": 3,# how many pices should the data be split into\n",
    "        \"number_of_replicas\": 2# how many copies of the data should be created\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting the documents\n",
    "'''\n",
    "* Tabular: all documents must have same fields \n",
    "* mapping: elastic search tries to figure out the data type of each field (we can set mannually)\n",
    "*  \n",
    "'''\n",
    "\n",
    "\n",
    "es.indices.delete(index=\"test_index\", ignore_unavailable=True)\n",
    "es.indices.create(index=\"test_index\")\n",
    "\n",
    "document = {\n",
    "    \"title\": \"some title\",\n",
    "    \"text\": \"some text\",\n",
    "    \"creation_date\":\"2025-05-01\"\n",
    "}\n",
    "response=es.index(index=\"test_index\", body=document)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert multiple documents (use for loop)\n",
    "def fucking_insert_multiple(es, index_name, document):\n",
    "    response = es.index(index=index_name, body=document)\n",
    "    return response\n",
    "\n",
    "for doc in [document]*2:\n",
    "    response = fucking_insert_multiple(es, \"my_index\", doc)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mapping\n",
    "from pprint import pprint\n",
    "\n",
    "index_mapping = es.indices.get_mapping(index=\"test_index\")\n",
    "pprint(index_mapping[\"test_index\"][\"mappings\"][\"properties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mannual mapping\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')\n",
    "\n",
    "mapping = {\n",
    "    'properties': {\n",
    "        'created_on': {'type': 'date'},\n",
    "        'text': {\n",
    "            'type': 'text',\n",
    "            'fields': {\n",
    "                'keyword': {\n",
    "                    'type': 'keyword',\n",
    "                    'ignore_above': 256\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'title': {\n",
    "            'type': 'text',\n",
    "            'fields': {\n",
    "                'keyword': {\n",
    "                    'type': 'keyword',\n",
    "                    'ignore_above': 256\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index', mappings=mapping)\n",
    "\n",
    "index_mapping = es.indices.get_mapping(index='my_index')\n",
    "\n",
    "'''\n",
    "# Alternative\n",
    "es.indices.put_mapping(index='my_index', body=mapping)\n",
    "\n",
    "index_mapping = es.indices.get_mapping(index='my_index')\n",
    "pprint(index_mapping[\"my_index\"][\"mappings\"][\"properties\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field data types\n",
    "'''\n",
    "* Binary field: \n",
    "  - not searchable and is not stored\n",
    "\n",
    "* boolean data field: True/false\n",
    "* numbers: long, integer, byte, short, ...\n",
    "* dates: \n",
    "* keywords: <to filter or sort> id, email, zip codes, ...\n",
    "\n",
    "'''\n",
    "\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary\n",
    "es.indices.delete(index='binary_index', ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index='binary_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"image_data\": {\n",
    "                \"type\": \"binary\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# insert\n",
    "import base64\n",
    "\n",
    "image_path = \"./the-imgae.png\"\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "    image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "print(f\"fucking inserted: {image_base64[:100]}...\")\n",
    "\n",
    "# get the image back\n",
    "document = {\n",
    "    \"image_data\": image_base64\n",
    "}\n",
    "response = es.index(index='binary_index', body=document)\n",
    "print(f\"fucking got: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects: (key value pairs like json data)\n",
    "es.indices.delete(index='object_index', ignore_unavailable=True)\n",
    "response = es.indices.create(\n",
    "    index='object_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"author\": {\n",
    "                \"properties\": {\n",
    "                    \"first_name\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"last_name\": {\n",
    "                        \"type\": \"text\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {response}\")\n",
    "\n",
    "document = {\n",
    "    \"author\": {\n",
    "        \"first_name\": \"Imad\",\n",
    "        \"last_name\": \"Saddik\"\n",
    "    }\n",
    "}\n",
    "response = es.index(index='object_index', body=document)\n",
    "print(f\"fucking document: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattened objects\n",
    "'''\n",
    "* Does not preserve relationship between fields. \n",
    "* e.g. for author with first and last names, it mixes up the first and last names\n",
    "'''\n",
    "\n",
    "es.indices.delete(index='flattened_object_index', ignore_unavailable=True)\n",
    "response = es.indices.create(\n",
    "    index='flattened_object_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"author\": {\n",
    "                \"type\": \"flattened\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {response}\")\n",
    "document = {\n",
    "    \"author\": {\n",
    "        \"first_name\": \"Imad\",\n",
    "        \"last_name\": \"Saddik\"\n",
    "    }\n",
    "}\n",
    "response = es.index(index='flattened_object_index', body=document)\n",
    "print(f\"fucking document response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested Objects (like nested json) (preserves the relation between fields)\n",
    "es.indices.delete(index='nested_object_index', ignore_unavailable=True)\n",
    "response = es.indices.create(\n",
    "    index='nested_object_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"user\": {\n",
    "                \"type\": \"nested\",\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {response}\")\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"first\": \"John\",\n",
    "        \"last\": \"Smith\"\n",
    "    },\n",
    "    {\n",
    "        \"first\": \"Imad\",\n",
    "        \"last\": \"Saddik\"\n",
    "    }\n",
    "]\n",
    "response = es.index(index='nested_object_index', body={\"user\": documents})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text search types\n",
    " - text is optimized for search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.delete(index='text_index', ignore_unavailable=True)\n",
    "response = es.indices.create(\n",
    "    index='text_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"email_body\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {response}\")\n",
    "\n",
    "document = {\n",
    "    \"email_body\": \"Hello, this is a test email.\"\n",
    "}\n",
    "response = es.index(index='text_index', body=document)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion : used to enable fast autocomplete suggestions by pre-indexing terms in a special way\n",
    "# when we enter things in gogle, it tries to auto complete the query\n",
    "\n",
    "es.indices.delete(index='text_completion_index', ignore_unavailable=True)\n",
    "response = es.indices.create(\n",
    "    index='text_completion_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"suggest\": {\n",
    "                \"type\": \"completion\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"fucking mapping response: \", es.indices.get_mapping(index='text_completion_index'))\n",
    "\n",
    "document_1 = {\n",
    "    \"suggest\": {\n",
    "        \"input\": [\"Mars\", \"Planet\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "document_2 = {\n",
    "    \"suggest\": {\n",
    "        \"input\": [\"Andromeda\", \"Galaxy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "es.index(index='text_completion_index', body=document_1)\n",
    "es.index(index='text_completion_index', body=document_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial data types\n",
    "\n",
    "# 1. GEo point\n",
    "response=es.indices.delete(index='geo_point_index', ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index='geo_point_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"geo_point\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {es.indices.get_mapping(index='geo_point_index')}\")\n",
    "\n",
    "document = {\n",
    "    \"text\": \"Geopoint as an object using GeoJSON format\",\n",
    "    \"location\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [\n",
    "            -71.34,\n",
    "            41.12\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "response = es.index(index='geo_point_index', body=document)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo shape: arbitary geographic shapes with multiple coordinates\n",
    "es.indices.delete(index='geo_shape_index', ignore_unavailable=True)\n",
    "response = es.indices.create(\n",
    "    index='geo_shape_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"geo_shape\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {es.indices.get_mapping(index='geo_shape_index')}\")\n",
    "\n",
    "document_1 = {\n",
    "    \"location\": {\n",
    "        \"type\": \"LineString\",\n",
    "        \"coordinates\": [\n",
    "            [\n",
    "                -77.03653,\n",
    "                38.897676\n",
    "            ],\n",
    "            [\n",
    "                -77.009051,\n",
    "                38.889939\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "document_2 = {\n",
    "    \"location\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "            [\n",
    "                [100, 0],\n",
    "                [101, 0],\n",
    "                [101, 1],\n",
    "                [100, 1],\n",
    "                [100, 0],\n",
    "            ],\n",
    "            [\n",
    "                [100.2, 0.2],\n",
    "                [100.8, 0.2],\n",
    "                [100.8, 0.8],\n",
    "                [100.2, 0.8],\n",
    "                [100.2, 0.2],\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "response_1 = es.index(index='geo_shape_index', body=document_1)\n",
    "print(response_1)\n",
    "es.index(index='geo_shape_index', body=document_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point\n",
    "es.indices.delete(index='point_index', ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index='point_index',\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"point\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"fucking mapping response: {es.indices.get_mapping(index='point_index')}\")\n",
    "\n",
    "\n",
    "document = {\n",
    "    \"location\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [\n",
    "            -71.34,\n",
    "            41.12\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.index(index='point_index', body=document)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert documents to delete\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "document_ids = []\n",
    "dummy_data = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    response = es.index(index='my_index', body=document)\n",
    "    document_ids.append(response['_id'])\n",
    "document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = es.delete(index='my_index', id=document_ids[2])\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to elastic\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert documents to get\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "document_ids = []\n",
    "dummy_data = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    response = es.index(index='my_index', body=document)\n",
    "    document_ids.append(response['_id'])\n",
    "document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get operation\n",
    "response = es.get(index='my_index', id=document_ids[0])\n",
    "response.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try getting non existant document\n",
    "try:\n",
    "    response = es.get(index='my_index', id=\"id\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count operation\n",
    "response = es.count(index='my_index')\n",
    "count = response[\"count\"]\n",
    "\n",
    "print(f\"The number of documents in the index is {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count operation with filters\n",
    "query = {\n",
    "    \"range\": {\n",
    "        \"created_on\": {\n",
    "            \"gte\": \"2024-09-24\",\n",
    "            \"lte\": \"2024-09-24\",\n",
    "            \"format\": \"yyyy-MM-dd\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es.count(index='my_index', query=query)\n",
    "count = response[\"count\"]\n",
    "\n",
    "print(f\"The number of documents in the index is {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if index exists\n",
    "response = es.indices.exists(index='my_index')\n",
    "response.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if document exists\n",
    "response = es.exists(index='my_index', id=document_ids[0])\n",
    "response.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update document\n",
    "* retrives document\n",
    "* perform update\n",
    "* save with different id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update existing field\n",
    "from pprint import pprint\n",
    "\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=document_ids[0],\n",
    "    script={\n",
    "        \"source\": \"ctx._source.title = params.title\",\n",
    "        \"params\": {\n",
    "            \"title\": \"New Title\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get updated document\n",
    "response = es.get(index='my_index', id=document_ids[0])\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new field\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=document_ids[0],\n",
    "    doc={\n",
    "        \"new_value_2\": \"dummy_value_2\",\n",
    "    },\n",
    ")\n",
    "pprint(response.body)\n",
    "\n",
    "response = es.get(index='my_index', id=document_ids[0])\n",
    "pprint(f\"\\n\\ndata with newly added field: {response.body}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (alternatively) add new field\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=document_ids[0],\n",
    "    script={\n",
    "        \"source\": \"ctx._source.new_field = 'dummy_value'\", # this is new field\n",
    "    },\n",
    ")\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get newly added field\n",
    "response = es.get(index='my_index', id=document_ids[0])\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a field\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=document_ids[0],\n",
    "    script={\n",
    "        \"source\": \"ctx._source.remove('new_field')\",\n",
    "    },\n",
    ")\n",
    "pprint(response.body)\n",
    "\n",
    "response = es.get(index='my_index', id=document_ids[0])\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsert: update or insert\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=\"1\",\n",
    "    doc={\n",
    "        \"book_id\": 1234,\n",
    "        \"book_name\": \"A book\",\n",
    "    },\n",
    "    doc_as_upsert=True,\n",
    ")\n",
    "pprint(f\"fucking saved: {response.body}\")\n",
    "\n",
    "response = es.count(index='my_index')\n",
    "pprint(f\"count: {response['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bulk operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert documents for bulk operations\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "document_ids = []\n",
    "dummy_data = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    response = es.index(index='my_index', body=document)\n",
    "    document_ids.append(response['_id'])\n",
    "document_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update first and second document\n",
    "from pprint import pprint\n",
    "\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=document_ids[0],\n",
    "    script={\n",
    "        \"source\": \"ctx._source.title = params.title\",\n",
    "        \"params\": {\n",
    "            \"title\": \"New Title\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "pprint(f\"fucking updated: {response.body}\")\n",
    "\n",
    "response = es.update(\n",
    "    index=\"my_index\",\n",
    "    id=document_ids[1],\n",
    "    script={\n",
    "        \"source\": \"ctx._source.new_field = 'dummy_value'\",\n",
    "    },\n",
    ")\n",
    "pprint(f\"fucking updated: {response.body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets delete the third document\n",
    "response = es.delete(index=\"my_index\", id=document_ids[2])\n",
    "pprint(f\"fucking deleted: {response.body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk operations\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')\n",
    "\n",
    "response = es.bulk(\n",
    "    operations=[\n",
    "        # Action 1: index\n",
    "        {\n",
    "            \"index\": {\n",
    "                \"_index\": \"my_index\",\n",
    "                \"_id\": \"1\"\n",
    "            }\n",
    "        },\n",
    "        # Source 1: on this document insert a new data\n",
    "        {\n",
    "            \"title\": \"Sample Title 1\",\n",
    "            \"text\": \"This is the first sample document text.\",\n",
    "            \"created_on\": \"2024-09-22\"\n",
    "        },\n",
    "        # Action 2: index\n",
    "        {\n",
    "            \"index\": {\n",
    "                \"_index\": \"my_index\",\n",
    "                \"_id\": \"2\"\n",
    "            }\n",
    "        },\n",
    "        # Source 2: on this document insert a new data\n",
    "        {\n",
    "            \"title\": \"Sample Title 2\",\n",
    "            \"text\": \"Here is another example of a document.\",\n",
    "            \"created_on\": \"2024-09-24\"\n",
    "        },\n",
    "        # Action 3: index\n",
    "        {\n",
    "            \"index\": {\n",
    "                \"_index\": \"my_index\",\n",
    "                \"_id\": \"3\"\n",
    "            }\n",
    "        },\n",
    "        # Source 3: on this document insert a new data\n",
    "        {\n",
    "            \"title\": \"Sample Title 3\",\n",
    "            \"text\": \"The content of the third document goes here.\",\n",
    "            \"created_on\": \"2024-09-24\"\n",
    "        },\n",
    "        # Action 4: update action\n",
    "        {\n",
    "            \"update\": {\n",
    "                \"_id\": \"1\",\n",
    "                \"_index\": \"my_index\"\n",
    "            }\n",
    "        },\n",
    "        # Source 4: on this document update the title\n",
    "        {\n",
    "            \"doc\": {\n",
    "                \"title\": \"New Title\"\n",
    "            }\n",
    "        },\n",
    "        # Action 5: update action\n",
    "        {\n",
    "            \"update\": {\n",
    "                \"_id\": \"2\",\n",
    "                \"_index\": \"my_index\"\n",
    "            }\n",
    "        },\n",
    "        # Source 5: on this document insert a new field\n",
    "        {\n",
    "            \"doc\": {\n",
    "                \"new_field\": \"dummy_value\"\n",
    "            }\n",
    "        },\n",
    "        # Action 6: delete action\n",
    "        {\n",
    "            \"delete\": {\n",
    "                \"_index\": \"my_index\",\n",
    "                \"_id\": \"3\"\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.body[\"errors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search api (part1)\n",
    "\n",
    "index: index_name\n",
    "q: simple search query (lucene like)\n",
    "query: more structured\n",
    "timeout: max time to wait for search result\n",
    "size: number of results to return\n",
    "from: starting index\n",
    "sort: sort results\n",
    "- _score: sort by relevance\n",
    "- _doc: sort by document order  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indexes\n",
    "es.indices.delete(index='index_1', ignore_unavailable=True)\n",
    "es.indices.create(index='index_1')\n",
    "\n",
    "es.indices.delete(index='index_2', ignore_unavailable=True)\n",
    "es.indices.create(index='index_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index sequentially in both indexes\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "dummy_data = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    response1 = es.index(index='index_1', body=document)\n",
    "print(f\"fucking response1 :{response1}\")\n",
    "\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    response2 = es.index(index='index_2', body=document)\n",
    "print(f\"fucking response2 :{response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search by index one at a time\n",
    "response = es.search(\n",
    "    index='index_1',\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in index_1\")\n",
    "\n",
    "\n",
    "\n",
    "response = es.search(\n",
    "    index='index_1',\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in index_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search by multiple indexes\n",
    "response = es.search(\n",
    "    index='index_1,index_2',\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in index_1 and index_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search by indexes starting with 'index'\n",
    "\n",
    "response = es.search(\n",
    "    index='index*',\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in all indexes with name starting with 'index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search all indexes\n",
    "response = es.search(\n",
    "    index='_all',\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in all indexes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search api part-2\n",
    "- Leaf clauses: match, term, range (can combine these)\n",
    "- compound clauses: bool \n",
    "\n",
    "- match: uses full text search that matches given text, number, ...\n",
    "- term: matches exact value: must be mapped to keyword or \n",
    "numeric or date \n",
    "- range: matches values within a range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to elastic\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)\n",
    "\n",
    "# Initializing new index\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')\n",
    "\n",
    "# inserting documents\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "dummy_data = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data.json\"))\n",
    "for document in tqdm(dummy_data, total=len(dummy_data)):\n",
    "    response = es.index(index='my_index', body=document)\n",
    "    pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search: leaf clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term query: documents created on 2024-09-22\n",
    "response = es.search(\n",
    "    index='my_index',\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"created_on\": \"2024-09-22\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in my_index\")\n",
    "\n",
    "retrieved_documents = response['hits']['hits']\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH query: containing word \"document\" in \"text\" field\n",
    "response = es.search(\n",
    "    index='my_index',\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": \"document\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in my_index\")\n",
    "\n",
    "retrieved_documents = response['hits']['hits']\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range query: created on or before 2024-09-23\n",
    "response = es.search(\n",
    "    index='my_index',\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"range\": {\n",
    "                \"created_on\": {\n",
    "                    \"lte\": \"2024-09-23\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in my_index\")\n",
    "\n",
    "retrieved_documents = response['hits']['hits']\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search: compound clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two leaf clause to find specific document\n",
    "response = es.search(\n",
    "    index='my_index',\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"bool\": { # bool: allows us to combine multiple conditions using logical operators (must, should, must_not, etc.).\n",
    "                \"must\": [ # both conditions must be true\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"text\": \"third\" #  full-text search on the \"text\" field for the word \"third\".\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"range\": {\n",
    "                            \"created_on\": { # filter documents created exactly on \"2024-09-24\"\n",
    "                                \"gte\": \"2024-09-24\",\n",
    "                                \"lte\": \"2024-09-24\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "n_hits = response['hits']['total']['value']\n",
    "print(f\"Found {n_hits} documents in my_index\")\n",
    "\n",
    "retrieved_documents = response['hits']['hits']\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to elastic search\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)\n",
    "\n",
    "# create index\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(index='my_index')\n",
    "\n",
    "\n",
    "# Inserting duplicate documents\n",
    "import json\n",
    "\n",
    "\n",
    "dummy_data = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data_2.json\"))\n",
    "for _ in range(10):\n",
    "    dummy_data += dummy_data\n",
    "\n",
    "print(f\"len dummy data: {len(dummy_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk api to index all those documents\n",
    "\n",
    "operations = []\n",
    "for document in dummy_data:\n",
    "    operations.append({'index': {'_index': 'my_index'}})\n",
    "    operations.append(document)\n",
    "\n",
    "es.bulk(operations=operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## searching: size + from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es.search(\n",
    "    index=\"my_index\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "        },\n",
    "        \"size\": 10,  # how many results (documents) to return in this request\n",
    "        \"from\": 10   #  The number of documents to skip (offset) before starting to return results.\n",
    "    },\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeout: Abort after timeout duration: partial result might still be returned\n",
    "\n",
    "response = es.search(\n",
    "    index=\"my_index\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"message\": \"search keyword\"\n",
    "            }\n",
    "        },\n",
    "        \"timeout\": \"10s\"\n",
    "    },\n",
    ")\n",
    "\n",
    "response.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation: average the value of age field across all documents\n",
    "# result of aggregation is stored in `avg_age` key.\n",
    "response = es.search(\n",
    "    index=\"my_index\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"avg_age\": {\n",
    "                \"avg\": {\n",
    "                    \"field\": \"age\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "average_age = response['aggregations']['avg_age']['value']\n",
    "print(f\"Average Age: {average_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining size, form, timeoutm aggs\n",
    "response = es.search(\n",
    "    index=\"my_index\",\n",
    "    body={\n",
    "        \"query\": { # query: find documents with important keyword\n",
    "            \"match\": {\n",
    "                \"message\": \"important keyword\"\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": { # aggergation: find max price and store it in max_price key\n",
    "            \"max_price\": {\n",
    "                \"max\": {\n",
    "                    \"field\": \"price\"\n",
    "                }  \n",
    "            }\n",
    "        },\n",
    "        \"size\": 5,  # return 5 results\n",
    "        \"from\": 20, # skip first 20 documents\n",
    "        \"timeout\": \"5s\" # timeout within 5 seconds\n",
    "    },\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_source'])\n",
    "\n",
    "max_price = response['aggregations']['max_price']['value']\n",
    "print(f\"Max Price: {max_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense vector field\n",
    "- vector of numeric values\n",
    "- dense means mostly non zero values\n",
    "- do not support sorting or aggrigation \n",
    "- use knn search for sorting and aggregation\n",
    "- have to do  the mapping mannually for vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource .venv/bin/activate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01melasticsearch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "!source .venv/bin/activate\n",
    "import elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01melasticsearch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "import elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to elasticsearch\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense vector requires manual mapping\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index=\"my_index\",\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"sides_length\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 4\n",
    "            },\n",
    "            \"shape\": {\n",
    "                \"type\": \"keyword\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid case: 1D array\n",
    "from pprint import pprint\n",
    "\n",
    "response = es.index(\n",
    "    index='my_index',\n",
    "    id=1,\n",
    "    document={\n",
    "        \"shape\": \"square\",\n",
    "        \"sides_length\": [5, 5, 5, 5],\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(response.body)\n",
    "\n",
    "pprint(es.indices.get_mapping(index='my_index').body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid case: 2D array (elasticsearch does not support multi dimensional arrays)\n",
    "response = es.index(\n",
    "    index='my_index',\n",
    "    id=2,\n",
    "    document={\n",
    "        \"shape\": \"square\",\n",
    "        \"sides_length\": [[5, 5], [5, 5]],\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "- Embedding transforms the text into vector of numbers\n",
    "- GPU is recommended for using open source embedding models\n",
    "- embedding models can be language specific or multi lingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to elastic search\n",
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index: since it is vector, we have to create index first\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index=\"my_index\",\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and device\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "import json\n",
    "\n",
    "documents = json.load(open(\"ElasticSearch_Python_Course/data/dummy_data.json\"))\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed documents, bulk insert\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "\n",
    "operations = []\n",
    "for document in tqdm(documents, total=len(documents)):\n",
    "    operations.append({'index': {'_index': 'my_index'}})\n",
    "    operations.append({\n",
    "        **document,\n",
    "        'embedding': get_embedding(document['text']),\n",
    "    })\n",
    "\n",
    "response = es.bulk(operations=operations)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve documents back to verify text was embedded correctly\n",
    "response = es.search(\n",
    "    index='my_index',\n",
    "    body={\n",
    "        'query':\n",
    "            {\n",
    "                'match_all': {}\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es.indices.get_mapping(index='my_index')\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn search \n",
    "- only applicable to dense vector fields\n",
    "- classification and regression tasks\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200')\n",
    "client_info = es.info()\n",
    "print('Connected to Elasticsearch!')\n",
    "pprint(client_info.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing index\n",
    "es.indices.delete(index='my_index', ignore_unavailable=True)\n",
    "es.indices.create(\n",
    "    index=\"my_index\",\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize device and model\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "import json\n",
    "\n",
    "\n",
    "documents = json.load(open(\"ElasticSearch_Python_Course/data/astronomy.json\"))\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and bulk insert documents\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "\n",
    "operations = []\n",
    "for document in tqdm(documents, total=len(documents)):\n",
    "    operations.append({'index': {'_index': 'my_index'}})\n",
    "    operations.append({\n",
    "        **document,\n",
    "        'embedding': get_embedding(document['content']),\n",
    "    })\n",
    "\n",
    "response = es.bulk(operations=operations)\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve documents to verify the text was converted to dense vector\n",
    "response = es.search(\n",
    "    index='my_index',\n",
    "    body={\n",
    "        'query':\n",
    "            {\n",
    "                'match_all': {}\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(response[\"hits\"][\"hits\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es.indices.get_mapping(index='my_index')\n",
    "pprint(response.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search after parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10 (main, Apr  9 2025, 04:03:51) [Clang 20.1.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "616bdcf3dc7b35d86424711b6c019cbadbee2904c84f89a48ad019be549f9559"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
