{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# added. to access data\n",
        "!git clone https://github.com/deep-learning-with-pytorch/dlwpt-code.git\n",
        "\n",
        "%cd dlwpt-code/p1ch6"
      ],
      "metadata": {
        "id": "YPSyfnvvZozL",
        "outputId": "f2c7e80f-dca7-45d8-fac0-0c0c0aa7ba20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dlwpt-code'...\n",
            "remote: Enumerating objects: 706, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 706 (delta 107), reused 89 (delta 87), pack-reused 554 (from 1)\u001b[K\n",
            "Receiving objects: 100% (706/706), 175.17 MiB | 18.15 MiB/s, done.\n",
            "Resolving deltas: 100% (319/319), done.\n",
            "Updating files: 100% (228/228), done.\n",
            "/content/dlwpt-code/p1ch6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_8lL3ERCZdDs"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iCOf8QE1ZdDt",
        "outputId": "3c8aab30-0e8a-44f4-f1b3-c630508b6cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=11, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=11, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "seq_model = nn.Sequential(\n",
        "            nn.Linear(1, 11), # <1>\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(11, 1)) # <1>\n",
        "seq_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dhGIkjYFZdDu",
        "outputId": "af76b861-1e56-4425-fff1-6b0574f79d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=12, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=12, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "namedseq_model = nn.Sequential(OrderedDict([\n",
        "    ('hidden_linear', nn.Linear(1, 12)),\n",
        "    ('hidden_activation', nn.Tanh()),\n",
        "    ('output_linear', nn.Linear(12 , 1))\n",
        "]))\n",
        "\n",
        "namedseq_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5rooZ5JAZdDv",
        "outputId": "16a39669-d77c-4e3b-f669-9f644d77a97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SubclassModel(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "class SubclassModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # <1>\n",
        "\n",
        "        self.hidden_linear = nn.Linear(1, 13)\n",
        "        self.hidden_activation = nn.Tanh()\n",
        "        self.output_linear = nn.Linear(13, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        hidden_t = self.hidden_linear(input)\n",
        "        activated_t = self.hidden_activation(hidden_t)\n",
        "        output_t = self.output_linear(activated_t)\n",
        "\n",
        "        return output_t\n",
        "\n",
        "subclass_model = SubclassModel()\n",
        "subclass_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eOvQ11sUZdDw",
        "outputId": "e883ff83-662d-4efc-ede3-532b0f55cc6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq\n",
            "0.weight              torch.Size([11, 1]) 11\n",
            "0.bias                torch.Size([11])    11\n",
            "2.weight              torch.Size([1, 11]) 11\n",
            "2.bias                torch.Size([1])     1\n",
            "\n",
            "namedseq\n",
            "hidden_linear.weight  torch.Size([12, 1]) 12\n",
            "hidden_linear.bias    torch.Size([12])    12\n",
            "output_linear.weight  torch.Size([1, 12]) 12\n",
            "output_linear.bias    torch.Size([1])     1\n",
            "\n",
            "subclass\n",
            "hidden_linear.weight  torch.Size([13, 1]) 13\n",
            "hidden_linear.bias    torch.Size([13])    13\n",
            "output_linear.weight  torch.Size([1, 13]) 13\n",
            "output_linear.bias    torch.Size([1])     1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for type_str, model in [('seq', seq_model),\n",
        "                        ('namedseq', namedseq_model),\n",
        "                        ('subclass', subclass_model)]:\n",
        "    print(type_str)\n",
        "    for name_str, param in model.named_parameters():\n",
        "        print(\"{:21} {:19} {}\".format(\n",
        "            name_str, str(param.shape), param.numel()))\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gy_MEJrHZdDy",
        "outputId": "77d24354-d7f8-4129-f7d7-00df0e7072c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SubclassFunctionalModel(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=14, bias=True)\n",
              "  (output_linear): Linear(in_features=14, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "class SubclassFunctionalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_linear = nn.Linear(1, 14)\n",
        "                                                # <1>\n",
        "        self.output_linear = nn.Linear(14, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        hidden_t = self.hidden_linear(input)\n",
        "        activated_t = torch.tanh(hidden_t) # <2>\n",
        "        output_t = self.output_linear(activated_t)\n",
        "\n",
        "        return output_t\n",
        "\n",
        "func_model = SubclassFunctionalModel()\n",
        "func_model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}