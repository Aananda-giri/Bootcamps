{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sHDpyS-kmoGJ",
        "outputId": "9e0933cf-8e2e-4c7d-e6d0-db94079cff28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-32e0d8fb07c9>:2: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1928.)\n",
            "  _ = torch.tensor([0.2126, 0.7152, 0.0722], names=['c'])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "_ = torch.tensor([0.2126, 0.7152, 0.0722], names=['c'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7b27RKdamoGM"
      },
      "outputs": [],
      "source": [
        "# imagine that we have a 3D tensor like img_t from section 2.1.4\n",
        "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
        "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jQycyvSpmoGO"
      },
      "outputs": [],
      "source": [
        "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TvP2JTSHmoGO",
        "outputId": "41c3ad69-b694-48d6-ab1c-a8e4afbe653a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "img_gray_naive = img_t.mean(-3)\n",
        "batch_gray_naive = batch_t.mean(-3)\n",
        "img_gray_naive.shape, batch_gray_naive.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UeGZcMI1moGP",
        "outputId": "fa0143ee-be9a-4e00-8514-cbec1d9ac0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# RGB channels are in dimension 0, and sometimes they are in dimension 1\n",
        "# But we can generalize by counting from the end: they are always in dimension â€“3, the third from the end\n",
        "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
        "img_weights = (img_t * unsqueezed_weights)\n",
        "batch_weights = (batch_t * unsqueezed_weights)\n",
        "img_gray_weighted = img_weights.sum(-3)\n",
        "batch_gray_weighted = batch_weights.sum(-3)\n",
        "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "unYT6zTcmoGQ",
        "outputId": "90d7d98a-33de-4d69-e44f-98242910dba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
        "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
        "batch_gray_weighted_fancy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NxaXdHmLmoGQ",
        "outputId": "4ba1cf06-3801-4509-d97f-8afa68d988cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
        "weights_named"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": false,
        "id": "V_mbmSa7moGR",
        "outputId": "f50a3af9-c36d-4e80-d90a-1dc79759ea18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
            "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
          ]
        }
      ],
      "source": [
        "# assign names to existing tensors\n",
        "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "print(\"img named:\", img_named.shape, img_named.names)\n",
        "print(\"batch named:\", batch_named.shape, batch_named.names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": false,
        "id": "sPx2Ao9GmoGR",
        "outputId": "df0bb5c6-a458-4f00-d807-8b0f13b80377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "weights_aligned = weights_named.align_as(img_named)\n",
        "weights_aligned.shape, weights_aligned.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "id": "AtNd97SCmoGS",
        "outputId": "17d6c5fb-fe73-4dd7-9629-59fdbaf15e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), ('rows', 'columns'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "gray_named = (img_named * weights_aligned).sum('channels')\n",
        "gray_named.shape, gray_named.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "id": "GkJMb3vKmoGT",
        "outputId": "15a44ab5-299b-41af-b203-b072986cd581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    gray_named = (img_named[..., :3] * weights_named).sum('channels')\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wmyxi_6gmoGT",
        "outputId": "d74c3e91-54eb-4b72-cf13-3ef9e3b995d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), (None, None))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "gray_plain = gray_named.rename(None)\n",
        "gray_plain.shape, gray_plain.names"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}